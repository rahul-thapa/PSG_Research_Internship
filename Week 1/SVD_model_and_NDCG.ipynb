{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVD_model_and_NDCG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cExS3HgMaJo7"
      },
      "source": [
        "#**Normalized Discounted Cumulative Gain**\n",
        "\n",
        "In this piece of code, we have seen the working of the normalized discounted cumulative gain or nDCG. For this, we took the help of SVD model which we applied on our dataset and calculated the nDCG for the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoK1MOc1G-H_"
      },
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jo21LzwHCqZ"
      },
      "source": [
        "import random\n",
        "from scipy.sparse import csr_matrix, dok_matrix\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJULA5--HMdj"
      },
      "source": [
        "**Param** *predictions*: The prediction object given by the model\n",
        "\n",
        "**Param** *n*: (default =10), The number of predictions to choose based on relevancy\n",
        "\n",
        "**Desciption:** The following function iterates over the prediction object and for each *uid* in the *predictions* object returns n number of most relevant results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRcLC50YHNch"
      },
      "source": [
        "def get_top_n(predictions, n=10):\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, true_r, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[2], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zmTZ42HN5Z"
      },
      "source": [
        "**Param** *user*: Represents the uid\n",
        "\n",
        "**Param** *predictions*: The prediction object given by the model\n",
        "\n",
        "**Desciption:** The following function iterates over the *predictions* for a particular *user* passed to the function and for each of the item in the *predictions* object, calculates the ratio of the **ground truth** to the **predicted truth**.\n",
        "The average values of these ratios are returned as a key-value pair."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQk3X1plHOKF"
      },
      "source": [
        "def calc_ndcg(user, predictions):\n",
        "\n",
        "    averageValues = []\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "        gt = predictions[i][1]  # ground truth\n",
        "        pt = predictions[i][2]  # predicted truth\n",
        "        if(pt > 0 and gt > 0):\n",
        "            ratio = gt/pt\n",
        "            averageValues.append(ratio)\n",
        "\n",
        "    ndcg = 0\n",
        "    for x in averageValues:\n",
        "        ndcg += x\n",
        "    ndcg = ndcg/(len(averageValues))\n",
        "    return {user: ndcg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPvg8stVJpde"
      },
      "source": [
        "### Reading Data\n",
        "Reading the data using pandas and loading the data-frame into the *data* variable using the *reader* helper method from **Surprise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCaKxd95JptZ"
      },
      "source": [
        "df = pd.read_csv('../rating.csv', sep=\"\\t\")\n",
        "print(df.head())\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "data = Dataset.load_from_df(df[['U_ID', 'P_ID', 'RATING']], reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi7vAVr8J1Wf"
      },
      "source": [
        "Splitting the data into train and test set in a 4:1 ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPmDKnPsKQwO"
      },
      "source": [
        "trainset, testset = train_test_split(data, test_size=.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joke9oyoKhhU"
      },
      "source": [
        "### Single Value Decomposition Model\n",
        "Defining the algorithm and training the algorithm on the trainset, and predict ratings for the testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHORGlcbKiOd"
      },
      "source": [
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "predictions = algo.test(testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pn0WzPMJ13C"
      },
      "source": [
        "predictions[1:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC39zgbvKv1n"
      },
      "source": [
        "Then compute Root Mean Square Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXyqLdSOKvEk"
      },
      "source": [
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R29nTuWLkGm"
      },
      "source": [
        "Testing the model and computing the NDCG values to measure the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryGb9l-bLRwW"
      },
      "source": [
        "top_n = get_top_n(predictions, n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9rDVXY_LsAI"
      },
      "source": [
        "top_n[1:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNxllmlzLS_X"
      },
      "source": [
        "ndcg_values_final = []\n",
        "\n",
        "itr = 0\n",
        "for uid, user_ratings in top_n.items():\n",
        "    res = calc_ndcg(uid, user_ratings)\n",
        "    ndcg_values_final.append(res[uid])\n",
        "    itr += 1\n",
        "    if itr > 20:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2pxZsVjZvtp"
      },
      "source": [
        "print(\"Final ndcg value: \", sum(ndcg_values_final)/len(ndcg_values_final))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}